{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains the code used to load a model and make predictions with that model. This model uses librosa instead of wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import librosa.display\n",
    "from librosa.feature import mfcc\n",
    "from librosa.feature import melspectrogram\n",
    "import wave\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local Variables\n",
    "# If you sync your google drive with your hard drive, you should be able to make everything work\n",
    "# by just changing the drive directory.\n",
    "drive_directory = \"E:\\\\Google Drive\\\\Big Data Project - Group 20\"\n",
    "# drive_directory = \"C:\\\\Users\\\\Owner\\\\Google Drive\\\\Big Data Project - Group 20\"\n",
    "notebook_directory = drive_directory + \"\\\\Code\\\\Sukris\\\\features-10_accuracy-81\"\n",
    "audio_directory = drive_directory + \"\\\\test_audio\"\n",
    "model_directory = notebook_directory + \"\\\\model\"\n",
    "sample_rate = 22050\n",
    "\n",
    "# Tuning Variables\n",
    "genres = ['blues','classical','country','disco','hiphop','jazz','metal','pop','reggae','rock']\n",
    "train_split = 0.8 # Percentage of data that will be used to train\n",
    "segment_width = 0.2 # Length of each audio segment in seconds\n",
    "num_frequencies = 128 # Number of frequency bins\n",
    "max_frequency = 4000 # Frequencies above this value will not be included\n",
    "num_epochs = 10 # Number of epochs to train with\n",
    "training_data_used = 1.0 # Percentage of the training data that is used\n",
    "test_data_used = 1.0 # Percentage of the test data that is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function predicts the genre and its confidence based on the input numpy data and model\n",
    "def predict_genre(frames,model):\n",
    "    \n",
    "    # Segment Data\n",
    "    print(\"Segmenting data...\")\n",
    "    sample_size = int(sample_rate * segment_width)\n",
    "    segments = []\n",
    "    c = 0\n",
    "    while True:\n",
    "        start = c * sample_size\n",
    "        end = start + sample_size\n",
    "        if end >= len(frames) * training_data_used:\n",
    "            break\n",
    "        segments.append(frames[start:end])\n",
    "        c += 1\n",
    "    segments = np.array(segments)\n",
    "        \n",
    "    # Get mfcc of segments\n",
    "    print(\"Taking MFCC of segments...\")\n",
    "    mfcc_arr = []\n",
    "    for s in segments:\n",
    "        mfcc_arr.append(mfcc(y=s, sr=sample_rate, n_mfcc=num_frequencies, fmax=max_frequency))\n",
    "    mfcc_arr = np.array(mfcc_arr)\n",
    "    \n",
    "    # Predict each segment\n",
    "    print(\"Making segment predictions...\")\n",
    "    counts = np.zeros(len(genres))\n",
    "    predictions = np.argmax(model.predict(mfcc_arr), axis=1)\n",
    "    for p in predictions:\n",
    "        counts[p] += 1\n",
    "    predictions = np.array(predictions)\n",
    "    counts = np.array(counts)\n",
    "    \n",
    "    # Predict the overall genre\n",
    "    genre_prediction = np.argmax(counts)\n",
    "    confidence = counts/len(predictions)\n",
    "    \n",
    "    return genre_prediction, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmenting data...\n",
      "Taking MFCC of segments...\n",
      "Making segment predictions...\n",
      "Predicted genre: metal\n",
      "Confidence:      0.8\n",
      "\n",
      "0.8 confidence for metal\n",
      "0.06 confidence for pop\n",
      "0.06 confidence for rock\n",
      "0.05 confidence for blues\n",
      "0.01 confidence for disco\n",
      "0.01 confidence for hiphop\n",
      "0.01 confidence for jazz\n",
      "0.0 confidence for classical\n",
      "0.0 confidence for country\n",
      "0.0 confidence for reggae\n"
     ]
    }
   ],
   "source": [
    "# Load the model and wav file\n",
    "# file_path = \"E:\\\\Google Drive\\\\My Jazz Stuff\\\\One Man Band\\\\Solar\\\\Solar Complete.wav\"\n",
    "# file_path = audio_directory + \"\\\\hiphop\\\\hiphop.00016.wav\"\n",
    "file_path = audio_directory + \"\\\\dream_theater_panic_attack.wav\"\n",
    "model = tf.keras.models.load_model(model_directory)\n",
    "print(\"Loading audio file...\")\n",
    "frames,_ = librosa.load(file_path, sr=sample_rate)\n",
    "\n",
    "# Make a prediction\n",
    "prediction,confidence = predict_genre(frames,model)\n",
    "\n",
    "# Round confidence values for readability\n",
    "confidence = np.round(confidence,2)\n",
    "\n",
    "# Sort based on confidence\n",
    "values_sorted = []\n",
    "g = genres.copy()\n",
    "c = confidence.copy().tolist()\n",
    "for _ in range(len(genres)):\n",
    "    i = np.argmax(c)\n",
    "    values_sorted.append((c[i],g[i]))\n",
    "    del c[i]\n",
    "    del g[i]\n",
    "\n",
    "# Display results\n",
    "print(\"Predicted genre:\", genres[prediction])\n",
    "print(\"Confidence:     \", np.max(confidence))\n",
    "print()\n",
    "for pair in values_sorted:\n",
    "    print(pair[0], \"confidence for\", pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1152)              1328256   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 576)               664128    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 288)               166176    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 288)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 144)               41616     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 144)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 72)                10440     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                730       \n",
      "=================================================================\n",
      "Total params: 2,211,346\n",
      "Trainable params: 2,211,346\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Google Drive\\Big Data Project - Group 20\\Code\\Sukris\\features-10_accuracy-81\\model\n",
      "C:\\Users\\Owner\\Google Drive\\Big Data Project - Group 20\\Code\\Sukris\\features-10_accuracy-81\\model\n"
     ]
    }
   ],
   "source": [
    "print(model_directory)\n",
    "print(\"C:\\\\Users\\\\Owner\\\\Google Drive\\\\Big Data Project - Group 20\\\\Code\\\\Sukris\\\\features-10_accuracy-81\\\\model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
